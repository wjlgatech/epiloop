{
  "project": "phase1-tier1-pattern-extraction",
  "branchName": "feature/tier1-pattern-extraction",
  "description": "Phase 1 of Option B: Extract high-value patterns from agent-zero into claude-loop. Implement hook system, learnings JSON, automatic task decomposition, and structured JSON output. 4 weeks, 4 user stories, foundational improvements that add extensibility and intelligence without external dependencies.",
  "context": {
    "background": "First phase of selective integration from ANALYSIS.md Option B. Focus on pattern extraction only - no library dependencies yet. These 4 features provide 60-80% of value with minimal risk. Subsequent phases (MCP, LiteLLM, delegation) will build on this foundation.",
    "references": [
      "/Users/jialiang.wu/Documents/Projects/benchmark-tasks/ANALYSIS.md",
      "/Users/jialiang.wu/Documents/Projects/agent-zero/python/",
      "/Users/jialiang.wu/Documents/Projects/claude-loop/claude-loop.sh"
    ],
    "constraints": [
      "No external library dependencies (pure bash + existing tools)",
      "Backward compatible: all features disabled by default via feature flags",
      "Preserve autonomous execution model",
      "File-based state management (no in-memory)",
      "Each feature independently testable and rollback-able"
    ]
  },
  "userStories": [
    {
      "id": "US-001",
      "title": "Implement Hook System for Lifecycle Extension",
      "description": "Add lifecycle hook system allowing users to inject custom bash scripts at key execution points. Inspired by agent-zero's 24 extension hooks and git hooks pattern. Enables surgical customization without modifying core code.",
      "acceptanceCriteria": [
        "Directory structure created: .claude-loop/hooks/{pre_iteration,post_iteration,pre_commit,post_commit,on_error,on_complete}/",
        "Hooks execute in alphanumeric order (01-99 prefix convention)",
        "Hook scripts receive context via environment variables: STORY_ID=$story_id, ITERATION=$iteration_number, WORKSPACE=$workspace_dir, BRANCH=$current_branch, PHASE=$current_phase",
        "Non-zero exit code from hook aborts execution with clear error message showing which hook failed",
        "Hook execution logged to .claude-loop/logs/hooks.jsonl with: {timestamp, hook_type, hook_name, exit_code, duration_ms, output}",
        "Feature flag: ENABLE_HOOKS=false by default in config, enable via --enable-hooks flag or config file",
        "Example hooks provided in .claude-loop/hooks/examples/: pre_iteration/10-check-dependencies.sh, post_commit/90-notify-slack.sh, on_error/50-create-issue.sh",
        "README.md section documenting hook system with complete API reference",
        "Hooks work correctly with parallel execution (git worktrees)",
        "Integration test: tests/hooks_test.sh validates all hook types"
      ],
      "priority": 1,
      "estimatedHours": 12,
      "dependencies": [],
      "technicalNotes": {
        "implementation": "Add hook_execute() function in claude-loop.sh. Call at strategic points: before/after iteration, before/after commit, on error, on completion. Load hooks from directory, sort by name, execute with proper env vars and error handling.",
        "reference": "See agent-zero/python/extensions/ for extension points. Git hooks in .git/hooks/ for pattern.",
        "testing": "Create test hooks that write to temp file, verify execution order and env vars passed correctly."
      },
      "passes": false
    },
    {
      "id": "US-002",
      "title": "Implement Lightweight Learnings JSON Storage",
      "description": "Create simple JSON-based storage for iteration learnings complementing existing ChromaDB experience store. Start with JSON for pragmatism (80% value, 5% complexity). Enables rating and querying patterns without FAISS overhead.",
      "acceptanceCriteria": [
        "File created: .claude-loop/learnings.json with schema: [{id: uuid, timestamp: iso8601, story_id, iteration, success: bool, lesson: string, tags: [string], helpful_count: int, context: {files, changes, duration}}]",
        "Append learnings after each iteration (atomic write, no file replacement)",
        "Query learnings by tags: query_learnings --tag 'error_handling' returns relevant lessons",
        "Include top 3 relevant learnings in prompt context based on story tags and description similarity",
        "CLI command: ./claude-loop.sh --list-learnings [--tag TAG] [--since DATE] displays learnings table",
        "CLI command: ./claude-loop.sh --rate-learning ID --helpful increments helpful_count",
        "CLI command: ./claude-loop.sh --rate-learning ID --unhelpful decrements helpful_count",
        "JSON schema validation on write (via jq)",
        "Automatic tagging: extract tags from story description and file paths",
        "Feature flag: ENABLE_LEARNINGS_JSON=false by default",
        "Performance: file size <10MB for 1000 learnings, query <100ms",
        "Documentation in README.md with examples and query syntax",
        "Integration test validates write, query, and rating operations"
      ],
      "priority": 2,
      "estimatedHours": 10,
      "dependencies": ["US-001"],
      "technicalNotes": {
        "implementation": "Add learnings_write(), learnings_query(), learnings_rate() functions. Use jq for JSON manipulation. Store in .claude-loop/learnings.json. For context injection, query learnings matching story tags and inject into prompt context.",
        "reference": "Simpler than agent-zero's FAISS memory but covers 80% of use cases. If >1000 learnings, consider migrating to FAISS later.",
        "dataStructure": "Single JSON array for simplicity. If performance issues, consider newline-delimited JSON (JSONL) for append efficiency."
      },
      "passes": false
    },
    {
      "id": "US-003",
      "title": "Implement Automatic Task Decomposition",
      "description": "Detect oversized stories via complexity analysis and automatically suggest decomposition into smaller substories. Use LLM to propose breakdown. Helps handle complex features by breaking them into manageable chunks.",
      "acceptanceCriteria": [
        "Complexity detection runs before story execution: analyze description, acceptance criteria, estimated hours, file count",
        "Thresholds: trigger decomposition if estimatedHours > 16 OR description length > 1000 chars OR acceptance_criteria count > 8",
        "LLM decomposition prompt: given story, suggest 2-5 substories with titles, descriptions, dependencies, and priority",
        "Interactive mode: present decomposition to user for approval (y/n/edit)",
        "Non-interactive mode: auto-approve with --auto-decompose flag",
        "Update PRD JSON: add substories with generated IDs (US-XXX-1, US-XXX-2, etc.), maintain parent reference, set dependencies, mark parent as 'decomposed'",
        "Substories inherit: tags, phase, context from parent story",
        "Decomposition logged to .claude-loop/logs/decomposition.jsonl with reasoning",
        "Feature flag: ENABLE_DECOMPOSITION=false by default",
        "CLI command: ./claude-loop.sh --decompose-story US-XXX forces decomposition",
        "Atomic PRD updates: backup before modification, rollback on failure",
        "Integration test: create oversized story, verify decomposition triggers and PRD updates correctly"
      ],
      "priority": 3,
      "estimatedHours": 16,
      "dependencies": ["US-002"],
      "technicalNotes": {
        "implementation": "Add complexity_check() and decompose_story() functions. Call complexity_check() at story start. If threshold exceeded, call LLM with decomposition prompt, parse response, update PRD JSON using jq.",
        "prompt": "Add decomposition prompt to prompt.md: 'Given this complex story, break it into 2-5 smaller, independent substories. For each substory provide: title, description (specific and actionable), estimated hours, dependencies.'",
        "prdUpdate": "Critical: use jq to modify PRD atomically. Create backup, modify, validate schema, commit or rollback."
      },
      "passes": false
    },
    {
      "id": "US-004",
      "title": "Implement Structured JSON Output Parser",
      "description": "Replace text-based sigil detection (<implement>, <commit>) with structured JSON output from Claude. Improves parsing reliability and enables richer metadata extraction (confidence, reasoning, related files).",
      "acceptanceCriteria": [
        "Update prompt.md: request JSON response format: {action: 'implement'|'commit'|'skip'|'delegate', reasoning: string, confidence: 0-100, files: [{path, changes}], metadata: {estimated_changes: int, complexity: int, related_files: []}}",
        "Parser handles both formats: new JSON output AND legacy sigil format (backward compatible)",
        "JSON schema validation: validate structure before processing",
        "Extract metadata: confidence score, estimated changes, complexity, related files",
        "Low-confidence handling: if confidence < 50, log warning and request clarification in next iteration",
        "Metadata logging: store parsed metadata in .claude-loop/logs/actions.jsonl",
        "Feature flag: ENABLE_STRUCTURED_OUTPUT=false by default, falls back to sigil parsing",
        "Performance: JSON parsing adds <100ms overhead per response",
        "Error handling: if JSON parsing fails, gracefully fall back to sigil detection with warning logged",
        "All existing integration tests pass with new parser (backward compatibility proof)",
        "New test: structured_output_test.sh validates JSON parsing and metadata extraction",
        "Documentation: README.md explains new JSON format and migration path"
      ],
      "priority": 4,
      "estimatedHours": 14,
      "dependencies": ["US-003"],
      "technicalNotes": {
        "implementation": "Add parse_json_response() function alongside existing parse_response_sigils(). Try JSON first, fall back to sigils. Use jq for JSON extraction. Update prompt.md to request JSON output when ENABLE_STRUCTURED_OUTPUT=true.",
        "backward_compatibility": "Critical: existing PRDs and workflows must work unchanged. Detect format (JSON vs sigil) automatically. Only use JSON when explicitly requested in prompt.",
        "testing": "Test both formats extensively. Verify all sigil-based tests still pass. Add new tests for JSON format."
      },
      "passes": false
    }
  ],
  "technicalContext": {
    "codebase": "Claude-loop: bash-based (4353 lines), PRD-driven, Git worktrees for parallelization, ChromaDB for experience, JSONL logging",
    "modificationPoints": [
      "claude-loop.sh: Add hook_execute(), learnings_write/query/rate(), complexity_check(), decompose_story(), parse_json_response() functions",
      "prompt.md: Add decomposition prompt, update to request JSON output",
      ".claude-loop/hooks/: New directory structure for hooks",
      ".claude-loop/learnings.json: New file for learnings storage",
      ".claude-loop/logs/: Add hooks.jsonl, decomposition.jsonl, actions.jsonl"
    ],
    "testStrategy": [
      "Unit tests: test individual functions (hooks, learnings, complexity check, JSON parser)",
      "Integration tests: tests/tier1_integration_test.sh covering all 4 features",
      "Regression tests: ensure existing PRDs still work",
      "Performance tests: measure overhead of each feature"
    ]
  },
  "successCriteria": {
    "functional": [
      "All 4 user stories implemented with acceptance criteria met",
      "Feature flags working: all features disabled by default, enableable individually",
      "Example artifacts created: sample hooks, sample learnings, example decomposition",
      "Documentation complete: README.md sections for each feature"
    ],
    "quality": [
      "All integration tests passing",
      "No regression in existing functionality",
      "Performance overhead <5% with all features enabled",
      "Code maintainable: functions modular, well-commented"
    ],
    "adoption": [
      "Clear migration path documented",
      "Example use cases provided",
      "Troubleshooting guide included",
      "Team can enable and use features independently"
    ]
  },
  "timeline": {
    "week1": "US-001 (Hook System) - 12 hours",
    "week2": "US-002 (Learnings JSON) - 10 hours",
    "week3": "US-003 (Task Decomposition) - 16 hours",
    "week4": "US-004 (Structured Output) - 14 hours",
    "totalHours": 52,
    "totalWeeks": 4,
    "bufferWeeks": 1
  },
  "rolloutPlan": {
    "phase": "Tier 1 Pattern Extraction",
    "nextPhase": "Tier 2 Library Integration (MCP, LiteLLM, Delegation)",
    "decisionPoint": "After Tier 1 completion, evaluate value delivered. If >20% improvement in DX or capability, proceed to Tier 2. Otherwise, stop here.",
    "rollback": "All features behind flags, can disable individually or collectively. Git revert to rollback code changes."
  }
}
