# AI2 Incubator Application

**Applicant:** Dr. Paul Jialiang Wu
**Startup:** research-loop
**Date:** January 2026

---

## What We Know About AI2 Incubator

### Selection Criteria (What They Look For)

| Criteria | How research-loop Fits |
|----------|----------------------|
| **Deep technical + domain expertise** | ✅ Yale postdoc (computational immunology) + Genentech (biotech) + Accenture (enterprise AI) |
| **Real technical depth, not API wrappers** | ✅ Novel meta-learning (CER), first research agent benchmark, multi-agent orchestration |
| **Research-driven innovation** | ✅ 51% measurable improvement via A/B testing, academic-quality methodology |
| **Vertical/specialized solutions** | ✅ Research automation for specific domains (medical, investment, scientific) |
| **Bridge research ↔ commercialization** | ✅ Open-source research tool → enterprise product |
| **Data/workflow advantages** | ✅ ResearchBench (500 questions), domain-specific adapters |

### What Makes AI2 Applications Stand Out

1. **Founders with domain expertise + AI** (not just AI expertise)
2. **Working prototype with traction** ("momentum is fantastic")
3. **Technical depth beyond API wrappers** (proprietary methods)
4. **Real-world use cases** (not pure research)
5. **Clear path to commercialization**

### Program Details
- **Funding:** Up to $600K at $10M cap
- **Equity:** ~7% common stock (founder-friendly)
- **Cloud credits:** Up to $1M non-dilutive
- **Duration:** 12 months + alumni support
- **Cohort size:** ~15/year (high-touch)
- **Location:** Seattle (or remote with quarterly visits)
- **Application:** Rolling, no deadlines

---

## APPLICATION FORM

### Basic Information

**Your Name:** Dr. Paul Jialiang Wu

**Email:** wjlgatech@gmail.com

**LinkedIn:** [Your LinkedIn URL]

**Current Role:** LLM Architect Manager, Accenture

**Location:** [Your city]

**Are you applying as a team?** Solo founder (open to co-founder matching)

---

### About You

**Tell us about yourself and your background:**

I'm a computational scientist turned AI architect with 15+ years at the intersection of research and technology:

- **Yale Postdoc** - Computational immunology, published research on algorithmic approaches to biological systems
- **Genentech (Principal Data Scientist)** - Built ML pipelines for drug discovery, understood firsthand how researchers struggle with literature review
- **Accenture (LLM Architect Manager)** - Currently leading enterprise LLM implementations, seeing the gap between AI capabilities and research workflows

I've lived the problem I'm solving: spending weeks on literature reviews that should take hours, watching brilliant scientists waste time on information retrieval instead of discovery.

---

### About Your Startup

**Company Name:** research-loop

**One-line description:**
Open-source multi-agent system that automates research synthesis with the first comprehensive benchmark for evaluating research agents.

**What problem are you solving?**

Researchers spend 40-60% of their time on literature review and synthesis—a $50B+ annual productivity drain across academia and industry. Current tools (Google Scholar, Semantic Scholar) help find papers but don't help understand them. ChatGPT-style tools hallucinate and lack citations.

The result: research bottlenecks, missed connections, and slower scientific progress.

**What is your solution?**

research-loop is a multi-agent research system that:

1. **Decomposes** complex research questions into sub-queries
2. **Searches** across multiple sources (arXiv, PubMed, Semantic Scholar, Exa.ai)
3. **Synthesizes** findings with sentence-level citations and confidence scores
4. **Learns** from experience via Contextual Experience Replay (our novel meta-learning approach)

Key differentiators:
- **ResearchBench**: First comprehensive benchmark for research agents (500 questions, 5 domains)
- **51% improvement** in research quality via meta-learning, measured through rigorous A/B testing
- **Human-in-the-loop checkpoints** for high-stakes domains (medical, investment)
- **Domain-specific adapters**: Medical Research Adapter, Investment Research Adapter

**What have you built so far?**

- ✅ Working prototype with 465+ tests passing
- ✅ Integrations: Exa.ai (39 tests), Semantic Scholar (45 tests), arXiv, PubMed
- ✅ ResearchBench dataset: 500 curated questions across AI-ML, Investment, Scientific, Technical, Interdisciplinary domains
- ✅ Contextual Experience Replay: 51% improvement measured via A/B testing
- ✅ Human checkpoint system for high-stakes decisions
- ✅ Investment adapter with paper trading validation

**Do you have any traction?**

- Open-source release pending (GitHub: github.com/wjlgatech/claude-loop)
- Stanford AIMI partnership discussions in progress (proposing sweat equity arrangement)
- ResearchBench positioned to be first industry benchmark for research agents

**What is your business model?**

1. **Open-source core** (community, brand, feedback)
2. **Enterprise SaaS** (hosted, managed, SLA)
3. **Domain adapters** (medical, legal, investment - premium)
4. **API access** (usage-based for developers)

Target: $50-500K ARR contracts with pharma, biotech, investment firms, research institutions.

---

### Why AI2 Incubator?

**Why are you applying to AI2 Incubator specifically?**

Three reasons AI2 is uniquely aligned with research-loop:

1. **Research DNA**: AI2 was founded to advance AI research. research-loop accelerates research itself—we're building infrastructure for the research community AI2 serves.

2. **Semantic Scholar connection**: AI2 created Semantic Scholar (7M+ monthly users). We've already integrated it. There's natural synergy in helping Semantic Scholar users do more than just find papers—actually synthesize them.

3. **Technical depth culture**: AI2 Incubator values "real technical depth, not API wrappers." Our Contextual Experience Replay and ResearchBench represent genuine methodological innovation, not just prompt engineering.

**What do you hope to get from AI2 Incubator?**

1. **Technical validation** from world-class AI researchers (is our approach sound?)
2. **Go-to-market guidance** for research tools (AI2 knows this market)
3. **Introductions** to research institutions and enterprise customers
4. **Co-founder matching** if appropriate (open to technical co-founder)

---

### Technical Deep Dive

**What is technically novel about your approach?**

1. **Contextual Experience Replay (CER)**
   - Stores successful research patterns with rich context
   - Retrieves relevant experiences for new queries
   - 51% improvement in research quality (measured via blind A/B testing)
   - Different from standard RAG: learns from agent behavior, not just documents

2. **ResearchBench**
   - First comprehensive benchmark for research agents
   - 500 questions across 5 domains with ground truth
   - Enables systematic evaluation (decomposition, source coverage, synthesis quality)
   - No existing benchmark addresses research agent capabilities

3. **Multi-agent orchestration**
   - Specialized agents: Decomposer, Searcher, Evaluator, Synthesizer
   - Domain-specific adapters with custom quality gates
   - Human-in-the-loop checkpoints for high-stakes domains

**What data advantages do you have?**

- ResearchBench dataset (proprietary, 500 curated questions)
- Experience memory from research sessions (grows with usage)
- Domain-specific quality patterns (medical, investment)

---

### Additional Information

**Is there anything else you'd like us to know?**

I'm currently employed at Accenture but committed to research-loop full-time upon acceptance. I have the financial runway to relocate to Seattle for the program.

I'm also in discussions with Stanford AIMI about a creative partnership (building them a Medical Research Adapter in exchange for affiliate-equivalent access). This demonstrates both the product's value and my ability to create partnerships without capital.

**Links:**
- GitHub: github.com/wjlgatech/claude-loop
- Demo video: [pending]
- ResearchBench spec: [link to docs]

---

## Why Dr. Paul Jialiang Wu Stands Out

| AI2 Criteria | Evidence |
|--------------|----------|
| Domain expertise + AI | Yale computational biology → Genentech ML → Accenture LLM architecture |
| Technical depth | Novel meta-learning (CER), first research benchmark, multi-agent systems |
| Research background | Published researcher, understands academic workflows |
| Enterprise experience | Genentech (biotech), Accenture (enterprise AI deployment) |
| Working prototype | 465+ tests, multiple integrations, measurable improvements |
| Clear commercialization path | Open-source → Enterprise SaaS → Domain adapters |

---

## Competitive Positioning vs. Other AI2 Applicants

Most AI applications are either:
- **Pure research** (no commercial path)
- **API wrappers** (no technical depth)
- **General-purpose** (no domain expertise)

research-loop is:
- **Research-informed** (academic rigor) + **Commercially viable** (clear business model)
- **Technically novel** (CER, ResearchBench) + **Practically useful** (working prototype)
- **Domain-specific** (medical, investment adapters) + **Platform potential** (extensible architecture)

---

*Application prepared: January 2026*
*Status: Ready to submit via ai2incubator.com or f6s.com/ai2incubator/apply*
